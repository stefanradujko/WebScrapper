type: edu
files:
- name: scraper.py
  visible: true
  learner_created: false
- name: tests.py
  visible: false
  text: |
    import glob
    import os
    import random
    import re
    import shutil
    import string

    import requests
    from bs4 import BeautifulSoup
    from furl import furl
    from hstest import *


    class NatureScraper:
        def tag_leading_to_view_article(self, tag):
            return tag.has_attr("data-track-action") and tag["data-track-action"] == "view article"

        def tag_containing_atricle_type(self, tag):
            return tag.name == "span" and tag.has_attr("data-test") and tag["data-test"] == "article.type"

        def tag_containing_article_title(self, tag):
            return tag.name == "h1" and ("article" in tag["class"][0] and "title" in tag["class"][0])

        def tag_containing_article_body(self, tag):
            return tag.name == "div" and ("article" in tag.get("class", [""])[0] and "body" in tag.get("class", [""])[0])

        def get_article_links_of_type(self, url, article_type="News"):
            origin_url = furl(url).origin
            try:
                articles_resp = requests.get(url)
            except Exception:
                raise WrongAnswer(f"ConnectionError occurred when tests tried to reach the page \'{url}\'.\n"
                                  f"Please try running tests again.")
            soup = BeautifulSoup(articles_resp.text, "html.parser")
            articles = soup.find_all(self.tag_containing_atricle_type)
            articles = list(filter(lambda x: x.text.strip() == article_type, articles))
            return [
                furl(origin_url).add(path=x.find_parent("article").find(self.tag_leading_to_view_article).get("href")).url \
                for x in articles]

        def get_article_title_and_content(self, url):
            try:
                article = requests.get(url)
            except Exception:
                return CheckResult.wrong("An error occurred when tests tried to connect to the Internet page.\n"
                                         "Please, try again.")
            soup = BeautifulSoup(article.text, "html.parser")
            title = soup.find(self.tag_containing_article_title)
            content = soup.find(self.tag_containing_article_body)
            if title and content:
                return title.text.strip(), content.text.strip()


    class WebScraperTest(StageTest):
        def generate(self):
            for name in os.listdir():
                if os.path.isdir(name) and name.startswith("Page_"):
                    shutil.rmtree(name)

            return [TestCase(stdin="3\nResearch Highlight", attach=(3, "Research Highlight"), time_limit=0),
                    TestCase(stdin="1\nNews & Views", attach=(1, "News & Views"), time_limit=0),
                    TestCase(stdin="2\nNews Feature", attach=(2, "News Feature"), time_limit=0)]

        def check(self, reply, attach=None):
            n_pages, article_type = attach
            scraper = NatureScraper()
            for i in range(1, n_pages + 1):
                dirname = f"Page_{i}"
                dirname = os.path.abspath(dirname)
                if not os.path.exists(dirname):
                    return CheckResult.wrong(f"Impossible to find directory {dirname}")
                os.chdir(dirname)
                txt_files = glob.glob("*.txt")
                url = furl("https://www.nature.com/nature/articles").add({"page": str(i)})
                article_links = scraper.get_article_links_of_type(url, article_type=article_type)
                if len(txt_files) != len(article_links):
                    return CheckResult.wrong("A wrong number of files with articles was found in the directory {0}. \n"
                                             "{1} files were found, {2} files were expected.".format(dirname,
                                                                                                     len(txt_files),
                                                                                                     len(article_links)))
                if article_links:
                    random_val = random.randint(0, len(article_links) - 1)
                    title, content = scraper.get_article_title_and_content(article_links[random_val])
                    content = content.strip()
                    title = f"{title.translate(str.maketrans('', '', string.punctuation)).replace(' ', '_')}.txt"
                    title = os.path.abspath(title)
                    if not os.path.exists(title):
                        return CheckResult.wrong("A file with the title {0} was expected, but was not found.".format(title))
                    with open(title, "rb") as f:
                        try:
                            file_content = f.read().decode('utf-8').strip()
                        except UnicodeDecodeError:
                            return CheckResult.wrong("An error occurred when tests tried to read the file \"{0}\"\n"
                                                     "Please, make sure you save your file in binary format \n"
                                                     "and encode the saved data using utf-8 encoding.".format(title))

                    file_content = re.sub('[\r\n]', '', file_content)
                    content = re.sub('[\r\n]', '', content)
                    if file_content != content:
                        return CheckResult.wrong("Some of the files do not contain the expected article's body. \n"
                                                 "The tests expected the following article:\n"
                                                 f"\"{content}\"\n"
                                                 f"However, the following text was found in the file {title}:\n"
                                                 f"\"{file_content}\"")
                os.chdir("..")
                try:
                    shutil.rmtree(dirname)
                except OSError as e:
                    print(f"The following error occurred when the tests tried to remove directory {dirname}:\n"
                          f"{e}\n"
                          f"If you can, please, make it possible to remove the directory.")
            return CheckResult.correct()


    if __name__ == '__main__':
        WebScraperTest().run_tests()
  learner_created: false
- name: This_‘super_antibody’_for_COVID_fights_off_multiple_coronaviruses.txt
  visible: true
  text: |-
    Antibodies (light blue; artist’s impression) swarm around a SARS-CoV-2 particle.Credit: Design Cells/SPL


    Scientists have uncovered an antibody that can fight off not only a wide range of SARS-CoV-2 variants, but also closely related coronaviruses1. The discovery could aid the quest to develop broad-ranging treatments and vaccines.Tyler Starr, a biochemist at the Fred Hutchinson Cancer Research Center in Seattle, Washington, and his co-authors set out to shed light on a problem facing antibody treatments for COVID-19: some variants of SARS-CoV-2 have acquired mutations that enable the virus to escape the antibodies’ grasp.The researchers examined 12 antibodies isolated from people who had recovered from COVID-19 by Vir Biotechnology, a company based in San Francisco, California, that was involved in the study. Those antibodies latch on to a fragment of viral protein that binds to receptors on human cells. Many antibody therapies for SARS-CoV-2 infection grab the same protein fragment, called the receptor binding domain.The researchers compiled a list of thousands of mutations in the binding domains of multiple SARS-CoV-2 variants. They also catalogued mutations in the binding domain on dozens of SARS-CoV-2-like coronaviruses that belong to a group called the sarbecoviruses. Finally, they assessed how all these mutations affect the 12 antibodies’ ability to stick to the binding domain.

    COVID and the brain: researchers zero in on how damage occurs
    One antibody, S2H97, stood out for its capacity to adhere to the binding domains of all the sarbecoviruses that the researchers tested. S2H97, which the authors dub a pan-sarbecovirus antibody, was able to prevent a range of SARS-CoV-2 variants and other sarbecoviruses from spreading among cells growing in the laboratory. It was also powerful enough to protect hamsters against SARS-CoV-2 infection. “That’s the coolest antibody that we described,” Starr says.A closer examination of S2H97’s molecular structure revealed that it targets a previously unseen and well-hidden region on the binding domain — a section that is revealed only when the domain pops up to bind to a cell’s receptor. Starr notes that molecules targeting this binding-domain region could generate protection against multiple viruses, and might one day be used in pan-sarbecovirus vaccines.The other 11 antibodies could target a variety of viruses, but the more effectively an antibody blocked the entry of the earliest known SARS-CoV-2 strain into a cell, the smaller the range of viruses it could bind. The team also found that antibodies that could disable a wide variety of viruses targeted sections of the binding domain that tended not to change as the virus evolved.It’s good news that the team has identified antibodies that can bind to a range of sarbecoviruses, says Arinjay Banerjee, a virologist at the University of Saskatchewan in Saskatoon, Canada. “The biggest question that remains is, what about viruses that we don’t know exist yet?”Although scientists can’t test an antibody’s activity against an unknown virus, Banerjee adds, pan-sarbecovirus treatments and vaccines would help to prepare the world to fight the next coronavirus that jumps from wildlife into humans.
  learner_created: true
feedback_link: https://hyperskill.org/projects/145/stages/785/implement#comment
status: Solved
feedback:
  message: Congratulations!
  time: Thu, 15 Jul 2021 13:59:43 UTC
record: -1
